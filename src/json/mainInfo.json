{
    "title": "GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming",
    "mainGif": "./videos/demo2.webm", 
    "authorList":[
        {
            "name": "author1",
            "url": "xxx"
        },
        {
            "name": "author2",
            "url": "xxx"
        },
        {
            "name": "author3",
            "url": "xxx"
        },
        {
            "name": "author4",
            "url": ""
        },
        {
            "name": "author5",
            "url": "xxx"
        },
        {
            "name": "author6",
            "url": "xxx"
        },
        {
            "name": "author7",
            "url": "xxx"
        },
        {
            "name": "author8",
            "url": "xxx"
        }
    ],
    "linkList":[
        {
            "name": "Paper",
            "img": "./img/paper_small.png",
            "url": "https://github.com/Coco-Robot/GhostShell"
        },
        {
            "name": "Code",
            "img": "./img/github.png",
            "url": "https://github.com/Coco-Robot/GhostShell"
        }
    ],
    "abstract": "We present GhostShell, a novel approach that leverages Large LanguageModels (LLMs) to enable streaming and concurrent behavioral programming for embodiedsystems. In contrast to conventional methods that rely on pre-scheduled action sequencesor behavior trees, GhostShell drives embodied systems to act on-the-fly by issuing functioncalls incrementally as tokens are streamed from the LLM. GhostShell features a streamingXML function token parser, a dynamic function interface mapper, and a multi-channelscheduler that orchestrates intra-channel synchronous and inter-channel asynchronousfunction calls, thereby coordinating serial-parallel embodied actions across multiple roboticcomponents as directed by the LLM. We benchmark GhostShell on our robot prototypeCOCO through extensive experiments, covering performance evaluation across representive LLMs, over one hundred real-world tasks, and comparisons against baselines built onLLMsâ€™ native function calling APIs. The results demonstrate that GhostShell outperformsnative function call baselines with faster response times and more flexible behaviororchestration. Among the evaluated LLMs, Claude Sonnet 4 consistently achieved the bestoverall performance. GhostShell also proved effective in long-horizon tasks, such as mirrorself-recognition and object-finding, demonstrating its strong robustness and generalization.",
    "mainImg": "./img/demo.png",
    "mainVideo": "./videos/demo.mp4",
    "ExperimentText1":"ExperimentText1ExperimentText1ExperimentText1ExperimentText1ExperimentText1",
    "ExperimentText2":"ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2ExperimentText2",
    "paperUrl":"https://github.com/Coco-Robot/GhostShell",
    "citationContent":"@inproceedings{codeaspolicies2022,<br/>title={Code as Policies: Language Model Programs for Embodied Control},<br/>author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},<br/>booktitle={arXiv preprint arXiv:2209.07753},<br/>year={2022}<br/>}",
    "acknowledgementsContent": "Special thanks to Vikas Sindhwani, Vincent Vanhoucke for helpful feedback on writing, Chad Boodoo for operations and hardware support."
}